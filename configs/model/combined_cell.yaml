# Cell classification model configuration
# Discriminative: ViT-B/16 (224x224 input)
# Generative: SiT-B/4 (512x512 input)

# Discriminative model: ViT-B/16
discriminative:
  model_name: "vit_base_patch16_224"
  pretrained: false  # Load from checkpoint instead
  checkpoint_path: null  # Set to trained ViT-B/16 checkpoint path
  num_classes: 5  # Number of cell classes (adjust based on your dataset)
  # Normalization settings (ImageNet defaults, used in training)
  normalize_mean: [0.485, 0.456, 0.406]
  normalize_std: [0.229, 0.224, 0.225]

# Pixel Adapter: shared between discriminative and generative branches
# pixel_adapter:
#   type: "standard"
#   in_channels: 3
#   hidden_channels: 64
#   num_blocks: 3
#   max_scale: 0.15
#   use_spatial_attention: true

# Generative model: SiT-B/4 (512x512 images)
generative:
  sit_model_name: "SiT-B/4"  # SiT-B/4 for 512x512 images
  sit_checkpoint: null  # Set to trained SiT-B/4 checkpoint path
  num_classes: 5  # Number of cell classes (must match discriminative)
  image_size: 512  # Diffusion model input size

  # VAE settings
  vae_pretrained: "stabilityai/sd-vae-ft-ema"
  vae_scaling_factor: 0.18215

  # Loss settings
  topk: 4
  rand_budget: 2
  normed_logit_scale: false
  normed_logit_scale_kwargs:
    s_max: 3.0
    h_thr: 0.015
    gamma: 3.0
  temperature: 1.0
  sample_reverse_logits: false
  adaptive_loss_weight: false
  kendall_topk: 8
  kendall_gate_only: true
  kendall_temperature: -1.0

  # Scheduler settings
  scheduler_type: "linear"
  # Timestep policy
  time_sampler_type: "thompson_sampling"
  time_sampler_kwargs:
    time_candidates: [0.18, 0.20, 0.215, 0.235, 0.25, 0.27, 0.29, 0.31, 0.33, 0.35, 0.39, 0.43, 0.48, 0.53, 0.57, 0.60]
