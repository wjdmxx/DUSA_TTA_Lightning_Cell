# Discriminative model: ConvNeXt-Large
discriminative:
  model_name: "convnext_large.fb_in1k"
  pretrained: true
  checkpoint_path: null  # Set to custom checkpoint path if needed
  num_classes: 1000
  # Normalization settings (applied in model forward)
  normalize_mean: [0.485, 0.456, 0.406]  # ImageNet mean
  normalize_std: [0.229, 0.224, 0.225]   # ImageNet std

# Pixel Adapter: shared between discriminative and generative branches
# Lives in CombinedModel, applied before both branches
pixel_adapter:
  type: "standard"
  in_channels: 3
  hidden_channels: 64
  num_blocks: 3
  max_scale: 0.15
  use_spatial_attention: true

# Generative model: REPA SiT
generative:
  sit_model_name: "SiT-XL/2"  # SiT-XL/2 or SiT-B/2
  sit_checkpoint: "/mnt/bit/liyuanxi/projects/DUSA_flow/classification/pretrained_models/REPA-SiT-XL-2-256.pt"  # UPDATE THIS
  num_classes: 1000
  
  # VAE settings
  vae_pretrained: "stabilityai/sd-vae-ft-ema"
  vae_scaling_factor: 0.18215
  
  # Loss settings
  topk: 4
  rand_budget: 2
  temperature: 1.0
  sample_reverse_logits: false
  
  # Scheduler settings
  scheduler_type: "linear"  # linear or reverse_linear
  time_sampler_type: "uniform"
  time_sampler_kwargs:
    t_min: 0.25
    t_max: 0.25
  
  # Adaptive loss weighting settings
  adaptive_loss_weight: false  # Enable adaptive sample-level loss weighting based on gap_norm
  adaptive_only_positive: false # Only use positive gap_norm for weighting, range in [1, max]
  adaptive_warmup_steps: 100   # Number of warmup steps before adaptive weighting kicks in
  adaptive_ema_decay: 0.99     # EMA decay factor for gap_norm tracking
  adaptive_weight_min: 0.8     # Minimum sample weight
  adaptive_weight_max: 1.5     # Maximum sample weight
  adaptive_gap_norm_std: 0.9   # Estimated std of gap_norm for scaling
